@article{0eacc694fb44dd8cc944d0bd8aad05a44603f79b,
title = {Calculon: a methodology and tool for high-level co-design of systems and large language models},
year = {2023},
url = {https://www.semanticscholar.org/paper/0eacc694fb44dd8cc944d0bd8aad05a44603f79b},
author = {Mikhail Isaev and Nic Mcdonald and Larry Dennison and R. Vuduc},
journal = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
volume = {null},
pages = {null},
doi = {10.1145/3581784.3607102},
}

@article{6a433d3cd43c22cbe23b700b9a1e0ee5cf631a8e,
title = {Rethinking Memory and Communication Cost for Efficient Large Language Model Training},
year = {2023},
url = {https://www.semanticscholar.org/paper/6a433d3cd43c22cbe23b700b9a1e0ee5cf631a8e},
author = {Chan Wu and Hanxiao Zhang and Lin Ju and Jinjing Huang and Youshao Xiao and Zhaoxin Huan and Siyuan Li and Fanzhuang Meng and Lei Liang and Xiaolu Zhang and Jun Zhou},
journal = {ArXiv},
volume = {abs/2310.06003},
pages = {null},
doi = {10.48550/arXiv.2310.06003},
arxivid = {2310.06003},
}

@article{43cefce076df7ee54505fd78a8a97129c0f6d36b,
title = {MPress: Democratizing Billion-Scale Model Training on Multi-GPU Servers via Memory-Saving Inter-Operator Parallelism},
year = {2023},
url = {https://www.semanticscholar.org/paper/43cefce076df7ee54505fd78a8a97129c0f6d36b},
author = {Quan Zhou and Haiquan Wang and Xiaoning Yu and Cheng Li and Youhui Bai and Feng Yan and Yinlong Xu},
journal = {2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA)},
volume = {null},
pages = {556-569},
doi = {10.1109/HPCA56546.2023.10071077},
}

@article{52f40b0fc2e51facbbbaaf63643e67843a3904b3,
title = {UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming},
year = {2023},
url = {https://www.semanticscholar.org/paper/52f40b0fc2e51facbbbaaf63643e67843a3904b3},
author = {Hao Lin and Ke Wu and Jun Yu Li and Wu-Jun Li},
journal = {ArXiv},
volume = {abs/2307.16375},
pages = {null},
doi = {10.48550/arXiv.2307.16375},
arxivid = {2307.16375},
}

@article{2d2b3fa757d7a839d6154b709f779366e624b903,
title = {Fold3D: Rethinking and Parallelizing Computational and Communicational Tasks in the Training of Large DNN Models},
year = {2023},
url = {https://www.semanticscholar.org/paper/2d2b3fa757d7a839d6154b709f779366e624b903},
author = {Fanxin Li and Shixiong Zhao and Yuhao Qing and Xusheng Chen and Xiuxian Guan and Sen Wang and Gong Zhang and Heming Cui},
journal = {IEEE Transactions on Parallel and Distributed Systems},
volume = {34},
pages = {1432-1449},
doi = {10.1109/TPDS.2023.3247883},
}

@article{10c0a1d3519dcc7b876d21d614f49d82467c9dc3,
title = {Parallel Training of Pre-Trained Models via Chunk-Based Dynamic Memory Management},
year = {2021},
url = {https://www.semanticscholar.org/paper/10c0a1d3519dcc7b876d21d614f49d82467c9dc3},
author = {Jiarui Fang and Yang Yu and Shenggui Li and Yang You and Jie Zhou},
journal = {IEEE Transactions on Parallel and Distributed Systems},
volume = {34},
pages = {304-315},
doi = {10.1109/TPDS.2022.3219819},
arxivid = {2108.05818},
}

@article{33ac6c15883552e54d68d7cef87b51c97f91b0a2,
title = {the 2021 USENIX},
year = {2021},
url = {https://www.semanticscholar.org/paper/33ac6c15883552e54d68d7cef87b51c97f91b0a2},
author = {Saar Eliad and Ido Hakimi and Alon De Jager and M. Silberstein and A. Schuster},
}

@article{bc8b82e8eb0b0714892e4ec7a54ebdf47c4fde96,
title = {Reducing Activation Recomputation in Large Transformer Models},
year = {2022},
url = {https://www.semanticscholar.org/paper/bc8b82e8eb0b0714892e4ec7a54ebdf47c4fde96},
author = {V. Korthikanti and J. Casper and Sangkug Lym and Lawrence C. McAfee and M. Andersch and M. Shoeybi and Bryan Catanzaro},
journal = {ArXiv},
volume = {abs/2205.05198},
pages = {null},
doi = {10.48550/arXiv.2205.05198},
arxivid = {2205.05198},
}

@article{adfe0e8eea02b4fff42ab02ecd778ce02c73bf7d,
title = {TAP: Accelerating Large-Scale DNN Training Through Tensor Automatic Parallelisation},
year = {2023},
url = {https://www.semanticscholar.org/paper/adfe0e8eea02b4fff42ab02ecd778ce02c73bf7d},
author = {Ziji Shi and Le Jiang and Ang Wang and J. Zhang and Xianyan Jia and Yong Li and Chencan Wu and Jialin Li and Wei Lin},
journal = {ArXiv},
volume = {abs/2302.00247},
pages = {null},
doi = {10.48550/arXiv.2302.00247},
arxivid = {2302.00247},
}

@article{509b16378deec0fb6bbec1d7aeb32a4bdeedddb1,
title = {GSPMD: General and Scalable Parallelization for ML Computation Graphs},
year = {2021},
url = {https://www.semanticscholar.org/paper/509b16378deec0fb6bbec1d7aeb32a4bdeedddb1},
author = {Yuanzhong Xu and HyoukJoong Lee and Dehao Chen and Blake A. Hechtman and Yanping Huang and Rahul Joshi and M. Krikun and Dmitry Lepikhin and Andy Ly and Marcello Maggioni and Ruoming Pang and Noam M. Shazeer and Shibo Wang and Tao Wang and Yonghui Wu and Zhifeng Chen},
journal = {ArXiv},
volume = {abs/2105.04663},
pages = {null},
arxivid = {2105.04663},
}

@article{283e56e843edc2ab599b0cf8218b936a89a11875,
title = {BPipe: Memory-Balanced Pipeline Parallelism for Training Large Language Models},
year = {2023},
url = {https://www.semanticscholar.org/paper/283e56e843edc2ab599b0cf8218b936a89a11875},
author = {Taebum Kim and Hyoungjoon Kim and Gyeong-In Yu and Byung-Gon Chun},
}

@article{00c957711b12468cb38424caccdf5291bb354033,
title = {ZeRO: Memory optimizations Toward Training Trillion Parameter Models},
year = {2019},
url = {https://www.semanticscholar.org/paper/00c957711b12468cb38424caccdf5291bb354033},
author = {Samyam Rajbhandari and Jeff Rasley and Olatunji Ruwase and Yuxiong He},
journal = {SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
volume = {null},
pages = {1-16},
doi = {10.1109/SC41405.2020.00024},
arxivid = {1910.02054},
}

@article{774591fdd988eaaff3917e7c5171d044b0843e63,
title = {Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM},
year = {2021},
url = {https://www.semanticscholar.org/paper/774591fdd988eaaff3917e7c5171d044b0843e63},
author = {D. Narayanan and M. Shoeybi and J. Casper and P. LeGresley and M. Patwary and V. Korthikanti and Dmitri Vainbrand and Prethvi Kashinkunti and J. Bernauer and Bryan Catanzaro and Amar Phanishayee and M. Zaharia},
journal = {SC21: International Conference for High Performance Computing, Networking, Storage and Analysis},
volume = {null},
pages = {1-14},
doi = {10.1145/3458817.3476209},
arxivid = {2104.04473},
}

@article{10f3ca78e194552427ebe9173b19d1b910469e27,
title = {Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines},
year = {2021},
url = {https://www.semanticscholar.org/paper/10f3ca78e194552427ebe9173b19d1b910469e27},
author = {Shigang Li and T. Hoefler},
journal = {SC21: International Conference for High Performance Computing, Networking, Storage and Analysis},
volume = {null},
pages = {1-14},
doi = {10.1145/3458817.3476145},
arxivid = {2107.06925},
}

@article{040ad14a2c97e51510889ae6a0c3c23b29da801d,
title = {TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models},
year = {2021},
url = {https://www.semanticscholar.org/paper/040ad14a2c97e51510889ae6a0c3c23b29da801d},
author = {Zhuohan Li and Siyuan Zhuang and Shiyuan Guo and Danyang Zhuo and Hao Zhang and D. Song and I. Stoica},
journal = {ArXiv},
volume = {abs/2102.07988},
pages = {null},
arxivid = {2102.07988},
}

@article{77e73174e606c0820a52a940088832b32d9a033e,
title = {Efficient Large-Scale Language Model Training on GPU Clusters},
year = {2021},
url = {https://www.semanticscholar.org/paper/77e73174e606c0820a52a940088832b32d9a033e},
author = {D. Narayanan and M. Shoeybi and J. Casper and P. LeGresley and M. Patwary and V. Korthikanti and Dmitri Vainbrand and Prethvi Kashinkunti and J. Bernauer and B. Catanzaro and Amar Phanishayee and M. Zaharia},
journal = {ArXiv},
volume = {abs/2104.04473},
pages = {null},
}

@article{4902436d2a6b91deab4f412988575729c3f98808,
title = {DistIR: An Intermediate Representation for Optimizing Distributed Neural Networks},
year = {2021},
url = {https://www.semanticscholar.org/paper/4902436d2a6b91deab4f412988575729c3f98808},
author = {Keshav Santhanam and Siddharth Krishna and Ryota Tomioka and A. Fitzgibbon and Tim Harris},
journal = {Proceedings of the 1st Workshop on Machine Learning and Systems},
volume = {null},
pages = {null},
doi = {10.1145/3437984.3458829},
}

@article{1a6a7fe065e42365515ccf7d0b5d1225b8088464,
title = {STRONGHOLD: Fast and Affordable Billion-Scale Deep Learning Model Training},
year = {2022},
url = {https://www.semanticscholar.org/paper/1a6a7fe065e42365515ccf7d0b5d1225b8088464},
author = {Xiaoyang Sun and Wen Wang and Shenghao Qiu and Renyu Yang and Songfang Huang and Jie Xu and Zheng Wang},
journal = {SC22: International Conference for High Performance Computing, Networking, Storage and Analysis},
volume = {null},
pages = {1-17},
doi = {10.1109/SC41404.2022.00076},
}

@article{ac04ed0f3ae0f5b269c9b3e0d1232007d60dbf7e,
title = {Memory-Efficient Pipeline-Parallel DNN Training},
year = {2020},
url = {https://www.semanticscholar.org/paper/ac04ed0f3ae0f5b269c9b3e0d1232007d60dbf7e},
author = {D. Narayanan and Amar Phanishayee and Kaiyu Shi and Xie Chen and M. Zaharia},
arxivid = {2006.09503},
}

@article{d5cfc82ac7ad6c5e9c91ef18bba6d2979b632443,
title = {Merak: An Efficient Distributed DNN Training Framework With Automated 3D Parallelism for Giant Foundation Models},
year = {2022},
url = {https://www.semanticscholar.org/paper/d5cfc82ac7ad6c5e9c91ef18bba6d2979b632443},
author = {Zhiquan Lai and Shengwei Li and Xudong Tang and Ke-shi Ge and Weijie Liu and Yabo Duan and Linbo Qiao and Dongsheng Li},
journal = {IEEE Transactions on Parallel and Distributed Systems},
volume = {34},
pages = {1466-1478},
doi = {10.1109/TPDS.2023.3247001},
arxivid = {2206.04959},
}

@article{1c9342ac9864fd4e75d77b6008ce69ddf35d3c14,
title = {Proteus: Simulating the Performance of Distributed DNN Training},
year = {2023},
url = {https://www.semanticscholar.org/paper/1c9342ac9864fd4e75d77b6008ce69ddf35d3c14},
author = {Jiangfei Duan and Xiuhong Li and Ping Xu and Xingcheng Zhang and Shengen Yan and Yun Liang and Dahua Lin},
journal = {ArXiv},
volume = {abs/2306.02267},
pages = {null},
doi = {10.48550/arXiv.2306.02267},
arxivid = {2306.02267},
}

@article{53fa6a6af93c2326f7830dca59b8ff4d2e1088ca,
title = {Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning},
year = {2022},
url = {https://www.semanticscholar.org/paper/53fa6a6af93c2326f7830dca59b8ff4d2e1088ca},
author = {Lianmin Zheng and Zhuohan Li and Hao Zhang and Yonghao Zhuang and Zhifeng Chen and Yanping Huang and Yida Wang and Yuanzhong Xu and Danyang Zhuo and Joseph Gonzalez and I. Stoica},
journal = {ArXiv},
volume = {abs/2201.12023},
pages = {null},
arxivid = {2201.12023},
}

@article{e8d6dc483b439c1e5ab839e86794ba301dabed88,
title = {Automated Tensor Model Parallelism with Overlapped Communication for Efficient Foundation Model Training},
year = {2023},
url = {https://www.semanticscholar.org/paper/e8d6dc483b439c1e5ab839e86794ba301dabed88},
author = {Shengwei Li and Zhiquan Lai and Yanqi Hao and Weijie Liu and Ke-shi Ge and Xiaoge Deng and Dongsheng Li and KaiCheng Lu},
journal = {ArXiv},
volume = {abs/2305.16121},
pages = {null},
doi = {10.48550/arXiv.2305.16121},
arxivid = {2305.16121},
}

@article{053c168f94acd75880acdacb846bc3f416e5c07c,
title = {PatrickStar: Parallel Training of Pre-trained Models via a Chunk-based Memory Management},
year = {2021},
url = {https://www.semanticscholar.org/paper/053c168f94acd75880acdacb846bc3f416e5c07c},
author = {Jiarui Fang and Yang Yu and Shenggui Li and Yang You and Jie Zhou},
journal = {ArXiv},
volume = {abs/2108.05818},
pages = {null},
}

@article{f74b387136d1d57a791c6b7c9d823577a47516aa,
title = {Harmony: Overcoming the hurdles of GPU memory capacity to train massive DNN models on commodity servers},
year = {2022},
url = {https://www.semanticscholar.org/paper/f74b387136d1d57a791c6b7c9d823577a47516aa},
author = {Youjie Li and Amar Phanishayee and D. Murray and Jakub Tarnawski and N. Kim},
journal = {Proc. VLDB Endow.},
volume = {15},
pages = {2747-2760},
doi = {10.14778/3551793.3551828},
arxivid = {2202.01306},
}

@article{9d4daa3c4fca89c05d971dffbdaf487461345bf6,
title = {AxoNN: An asynchronous, message-driven parallel framework for extreme-scale deep learning},
year = {2021},
url = {https://www.semanticscholar.org/paper/9d4daa3c4fca89c05d971dffbdaf487461345bf6},
author = {Siddharth Singh and A. Bhatele},
journal = {2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
volume = {null},
pages = {606-616},
doi = {10.1109/ipdps53621.2022.00065},
arxivid = {2110.13005},
}

@article{e51578b433b7cf7cb92febd4fcd8b78035f08ff9,
title = {Breadth-First Pipeline Parallelism},
year = {2022},
url = {https://www.semanticscholar.org/paper/e51578b433b7cf7cb92febd4fcd8b78035f08ff9},
author = {J. Lamy-Poirier},
journal = {ArXiv},
volume = {abs/2211.05953},
pages = {null},
doi = {10.48550/arXiv.2211.05953},
arxivid = {2211.05953},
}

@article{6866e92fecae173e41d5b78110f916cd95b7644e,
title = {Survey on Efficient Training of Large Neural Networks},
year = {2022},
url = {https://www.semanticscholar.org/paper/6866e92fecae173e41d5b78110f916cd95b7644e},
author = {Julia Gusak and Daria Cherniuk and Alena Shilova and A. Katrutsa and Daniel Bershatsky and Xunyi Zhao and Lionel Eyraud-Dubois and Oleh Shliazhko and Denis Dimitrov and I. Oseledets and Olivier Beaumont},
doi = {10.24963/ijcai.2022/769},
}

@article{baa467a4dccf87bc7e2c5a4ea6fd5e401d962d39,
title = {AutoPipe: A Fast Pipeline Parallelism Approach with Balanced Partitioning and Micro-batch Slicing},
year = {2022},
url = {https://www.semanticscholar.org/paper/baa467a4dccf87bc7e2c5a4ea6fd5e401d962d39},
author = {Weijie Liu and Zhiquan Lai and Shengwei Li and Yabo Duan and Ke-shi Ge and Dongsheng Li},
journal = {2022 IEEE International Conference on Cluster Computing (CLUSTER)},
volume = {null},
pages = {301-312},
doi = {10.1109/CLUSTER51413.2022.00042},
}

@article{8268f2312602bccd0d8d91aa28737843e428c3f3,
title = {Fine-tuning giant neural networks on commodity hardware with automatic pipeline model parallelism},
year = {2021},
url = {https://www.semanticscholar.org/paper/8268f2312602bccd0d8d91aa28737843e428c3f3},
author = {Saar Eliad and Ido Hakimi and Alon De Jagger and M. Silberstein and Assaf Schuster},
}

@article{4c693370ddeaa37d5534e3c59becbe419aba6cd7,
title = {Survey on Large Scale Neural Network Training},
year = {2022},
url = {https://www.semanticscholar.org/paper/4c693370ddeaa37d5534e3c59becbe419aba6cd7},
author = {Julia Gusak and Daria Cherniuk and Alena Shilova and A. Katrutsa and Daniel Bershatsky and Xunyi Zhao and Lionel Eyraud-Dubois and Oleg Shlyazhko and Denis Dimitrov and I. Oseledets and Olivier Beaumont},
journal = {ArXiv},
volume = {abs/2202.10435},
pages = {null},
arxivid = {2202.10435},
}

@article{be157d55b4afd5be9c81619d75aa4897f5e201e4,
title = {Elixir: Train a Large Language Model on a Small GPU Cluster},
year = {2022},
url = {https://www.semanticscholar.org/paper/be157d55b4afd5be9c81619d75aa4897f5e201e4},
author = {Haichen Huang and Jiarui Fang and Hongxin Liu and Shenggui Li and Yang You},
journal = {ArXiv},
volume = {abs/2212.05339},
pages = {null},
doi = {10.48550/arXiv.2212.05339},
arxivid = {2212.05339},
}

@article{bea8f5d6cf70402b21721b7ddf458286ef7af775,
title = {Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models},
year = {2023},
url = {https://www.semanticscholar.org/paper/bea8f5d6cf70402b21721b7ddf458286ef7af775},
author = {Yuliang Liu and Shenggui Li and Jiarui Fang and Yan Shao and Boyuan Yao and Yang You},
journal = {ArXiv},
volume = {abs/2302.02599},
pages = {null},
doi = {10.48550/arXiv.2302.02599},
arxivid = {2302.02599},
}

@article{4506c9cd34a0b6f09fe23a3d9be0bc0962d14540,
title = {ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep learning},
year = {2021},
url = {https://www.semanticscholar.org/paper/4506c9cd34a0b6f09fe23a3d9be0bc0962d14540},
author = {Samyam Rajbhandari and Olatunji Ruwase and Jeff Rasley and Shaden Smith and Yuxiong He},
journal = {SC21: International Conference for High Performance Computing, Networking, Storage and Analysis},
volume = {null},
pages = {1-15},
doi = {10.1145/3458817.3476205},
arxivid = {2104.07857},
}

@article{58d6ec0dec4952e93be7cf72c1cebb0216eac9df,
title = {Mobius: Fine Tuning Large-Scale Models on Commodity GPU Servers},
year = {2023},
url = {https://www.semanticscholar.org/paper/58d6ec0dec4952e93be7cf72c1cebb0216eac9df},
author = {Yangyang Feng and Minhui Xie and Zijie Tian and Shuo Wang and Youyou Lu and J. Shu},
journal = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
volume = {null},
pages = {null},
doi = {10.1145/3575693.3575703},
}

@article{0437f76a8e6607116659f16c7e4e656851fdd9d5,
title = {HPH: Hybrid Parallelism on Heterogeneous Clusters for Accelerating Large-scale DNNs Training},
year = {2022},
url = {https://www.semanticscholar.org/paper/0437f76a8e6607116659f16c7e4e656851fdd9d5},
author = {Yabo Duan and Zhiquan Lai and Shengwei Li and Weijie Liu and Ke-shi Ge and Peng Liang and Dongsheng Li},
journal = {2022 IEEE International Conference on Cluster Computing (CLUSTER)},
volume = {null},
pages = {313-323},
doi = {10.1109/CLUSTER51413.2022.00043},
}

@article{aa6ddad0a84eaa004e49142981d05c5f36cc585e,
title = {Hanayo: Harnessing Wave-like Pipeline Parallelism for Enhanced Large Model Training Efficiency},
year = {2023},
url = {https://www.semanticscholar.org/paper/aa6ddad0a84eaa004e49142981d05c5f36cc585e},
author = {Ziming Liu and Shenggan Cheng and Hao Zhou and Yang You},
journal = {The International Conference for High Performance Computing, Networking, Storage, and Analysis},
volume = {null},
pages = {null},
doi = {10.1145/3581784.3607073},
arxivid = {2308.15762},
}

@article{f6ba3fab410cf2182fde171beeeec57bffa3e90b,
title = {SuperScaler: Supporting Flexible DNN Parallelization via a Unified Abstraction},
year = {2023},
url = {https://www.semanticscholar.org/paper/f6ba3fab410cf2182fde171beeeec57bffa3e90b},
author = {Zhiqi Lin and Youshan Miao and Guodong Liu and Xiaoxiang Shi and Quanlu Zhang and Fan Yang and Saeed Maleki and Yi Zhu and Xu Cao and Cheng-Wu Li and Mao Yang and Lintao Zhang and Lidong Zhou},
journal = {ArXiv},
volume = {abs/2301.08984},
pages = {null},
doi = {10.48550/arXiv.2301.08984},
arxivid = {2301.08984},
}

@article{7039f7f662a55b49288a7db11e07a9cf4e465a8b,
title = {PatrickStar: Parallel Training of Pre-trained Models via Chunk-based Memory Management},
year = {2021},
url = {https://www.semanticscholar.org/paper/7039f7f662a55b49288a7db11e07a9cf4e465a8b},
author = {Jiarui Fang},
}

@article{ba733319b0878ac9b9b161c52749c6ef7af9a61e,
title = {Myelin: An asynchronous, message-driven parallel framework for extreme-scale deep learning},
year = {2021},
url = {https://www.semanticscholar.org/paper/ba733319b0878ac9b9b161c52749c6ef7af9a61e},
author = {Siddharth Singh and A. Bhatele},
journal = {ArXiv},
volume = {abs/2110.13005},
pages = {null},
}

@article{793f7284ccaa6c2cd530e6d405f5fa75bfd283e8,
title = {Scaling Infrastructure to Support Multi-Trillion Parameter LLM Training},
year = {2023},
url = {https://www.semanticscholar.org/paper/793f7284ccaa6c2cd530e6d405f5fa75bfd283e8},
author = {Mikhail Isaev and Nic McDonald and R. Vuduc},
}
